{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a2d302",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy,AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve\n",
    "import itertools\n",
    "import cv2\n",
    "import scipy.integrate as integrate\n",
    "import scipy\n",
    "from tensorflow.keras.applications import VGG16\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications import ResNet50,ResNet101\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5b543",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = 'train'  # path to the folder containing the dataset\n",
    "test_dir = 'test'\n",
    "img_width = 256  # width of the images\n",
    "img_height = 256  # height of the images\n",
    "batch_size = 32  # batch size for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removing Corrupted Images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_corrupted_images():\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                img = tf.keras.preprocessing.image.load_img(file_path, target_size=(img_width, img_height))\n",
    "                img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            except:\n",
    "                os.remove(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "remove_corrupted_images()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_corrupted_test():\n",
    "    for folder in os.listdir(test_dir):\n",
    "        folder_path = os.path.join(test_dir, folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                img = tf.keras.preprocessing.image.load_img(file_path, target_size=(img_width, img_height))\n",
    "                img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            except:\n",
    "                os.remove(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "remove_corrupted_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spliting the datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_set = train_datagen.flow_from_directory(data_dir,\n",
    "                                              target_size=(img_width, img_height),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='training')\n",
    "valid_set = train_datagen.flow_from_directory(data_dir, target_size=(img_width, img_height),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='validation')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(test_dir, target_size=(img_width, img_height),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical',\n",
    "                                            shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the Deep Learning Classification model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#CONV 1\n",
    "model.add(Conv2D(filters= 32,kernel_size= (3, 3),strides=(3,3),padding='valid', activation='relu', input_shape=(img_width, img_height, 3))) #32 kernels/filters , kernel_size 3x3\n",
    "model.add(MaxPooling2D(pool_size= (2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#CONV 2\n",
    "model.add(Conv2D(filters=64,kernel_size= (3, 3),padding='same', activation='relu',strides=(1,1),kernel_regularizer=l2(0.0005))) #increased the depth to 64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#CONV 3\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3),padding='same', activation='relu',strides=(1,1),kernel_regularizer=l2(0.0005))) #increased the depth to 64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\n",
    "#CONV 4\n",
    "model.add(Conv2D(filters=128,kernel_size= (3, 3),padding='same', activation='relu',strides=(1,1),kernel_regularizer=l2(0.0005)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#CONV 5\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3),padding='same', activation='relu',strides=(1,1),kernel_regularizer=l2(0.0005)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#CONV 6\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3),padding='same', activation='relu',strides=(1,1),kernel_regularizer=l2(0.0005)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#CONV 7\n",
    "model.add(Conv2D(filters=512, kernel_size=(3, 3),padding='same', activation='relu',strides=(1,1),kernel_regularizer=l2(0.0005)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())  #flattern, since there are too many dimensions; we only want a classification output\n",
    "\n",
    "#CONV 8\n",
    "model.add(Dense(units= 512, activation='relu')) #FC1: Fully connects to get all relevant data\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(units=3, activation='softmax')) #FC2: Outputs a softmax to squash the matrix into output probabilities for the 3 classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze pre-trained layers in VGG16\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create new model with VGG16 as base\n",
    "model = Sequential()\n",
    "model.add(vgg16)\n",
    "\n",
    "# Add custom layers for classification\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50 model\n",
    "resnet101 = ResNet101(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze pre-trained layers in ResNet50\n",
    "for layer in resnet101.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create new model with ResNet50 as base\n",
    "model = Sequential()\n",
    "model.add(resnet101)\n",
    "\n",
    "# Add custom layers for classification\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.00001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a callback to save checkpoints during training\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='checkpoints/cervical_cancer_screening_model-{epoch:02d}.h5',\n",
    "                                                         monitor='val_loss',\n",
    "                                                         verbose=1,\n",
    "                                                         save_best_only=True,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         mode='auto')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logdir='logs'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist =  model.fit(train_set, epochs=30, validation_data=valid_set, callbacks=[tensorboard_callback,checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perfomance Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.history\n",
    "\n",
    "for epoch in range(len(history.history['loss'])):\n",
    "    loss = history.history['loss'][epoch]\n",
    "    accuracy = history.history['accuracy'][epoch]\n",
    "    print(f'Epoch {epoch}: loss = {loss}, accuracy = {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the weights from the last saved checkpoint\n",
    "model.load_weights('checkpoints/cervical_cancer_screening_model-17.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the predicted classes for the test set\n",
    "y_pred = model.predict(test_set)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_set.classes, y_pred_classes, labels=None)\n",
    "\n",
    "# Define the class labels\n",
    "class_names = ['Negative', 'Positive','Suspected']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "fmt = 'd'\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "    plt.text(j, i, format(conf_matrix[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.pdf',format='pdf',bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate true positives, false positives, true negatives, and false negatives from the confusion matrix\n",
    "tp = conf_matrix[1,1]\n",
    "fp = conf_matrix[0,1]\n",
    "tn = conf_matrix[0,0]\n",
    "fn = conf_matrix[1,0]\n",
    "\n",
    "# Calculate accuracy precision and recall\n",
    "Accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "F_Score = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print('Accuracy:', np.round(Accuracy *100,4))\n",
    "print('Precision:', np.round(precision*100,4))\n",
    "print('Recall:', np.round(recall*100,4))\n",
    "print('F-Score:', np.round(F_Score*100,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate true positives, false positives, true negatives, and false negatives from the confusion matrix\n",
    "tp = 195\n",
    "fp = 46\n",
    "tn = 179\n",
    "fn = 32\n",
    "\n",
    "# Calculate accuracy precision and recall\n",
    "Accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "F_Score = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print('Accuracy:', np.round(Accuracy *100,4))\n",
    "print('Precision:', np.round(precision*100,4))\n",
    "print('Recall:', np.round(recall*100,4))\n",
    "print('F-Score:', np.round(F_Score*100,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the predicted probabilities\n",
    "y_pred_prob = model.predict(test_set)\n",
    "\n",
    "# Check the shape of the predicted probabilities\n",
    "if y_pred_prob.ndim > 1 and y_pred_prob.shape[1] > 1:\n",
    "    # Get the predicted probabilities for the positive class\n",
    "    y_pred_prob = y_pred_prob[:, 1]\n",
    "\n",
    "# Compute the AUC score\n",
    "auc_score = roc_auc_score(y_true, y_pred_prob)\n",
    "\n",
    "# Print the AUC score\n",
    "print('AUC score:', auc_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC Curve (area = 0.96)')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('AUC.pdf',format='pdf',bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the model to json format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the Model for deployment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','cervical_cancer_image_classifier.h5'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_model = load_model('./models/cervical_cancer_image_classifier.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "# Load the image and resize it to the required size for the model\n",
    "img = image.load_img('data_set/Positive/4225.jpg', target_size=(256, 256))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Expand the dimensions of the array to match the input shape of the model\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Make a prediction using the model\n",
    "preds = new_model.predict(img_array)\n",
    "\n",
    "# Get the index of the class with the highest probability\n",
    "class_idx = np.argmax(preds, axis=1)[0]\n",
    "\n",
    "# Define a list of class labels\n",
    "class_labels = ['Negative', 'Positive','Suspected']\n",
    "\n",
    "# Get the corresponding class label for the predicted class index\n",
    "class_label = class_labels[class_idx]\n",
    "\n",
    "# Print the predicted class label\n",
    "print('Predicted class:', class_label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}